name: CI Build and Test

on: [pull_request]

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Generate matrix from CSV
        id: set-matrix
        run: |
          MATRIX_JSON=$(.github/workflows/scripts/generate_ci_matrix.py)
          echo "matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT

  build:
    needs: generate-matrix
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
    # Host OS and CPU
    runs-on: ${{ matrix.instance.img }}

    # Use htcondor build containers for the real work
    container:
      image: ${{ matrix.instance.container }}
      env:
        OMP_NUM_THREADS: 4
      volumes:
        - my_docker_volume:/volume_mount
      options: --cpus 4 --hostname build-${{ matrix.instance.abbrev }}.chtc.wisc.edu
    steps:
      - name: Create Platform Name
        id: platform_name
        run: echo "platform_name=$(echo ${{ matrix.instance.container }} | sed -e 's/htcondor\/nmi-build://g' -e 's/-[0-9]*$//g')" >> $GITHUB_OUTPUT

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build
        run: |
          # Hackery for using toolset gcc instead of default
          if [ -f "/opt/rh/gcc-toolset-14/root/usr/bin/gcc" ]; then
            export CC=/opt/rh/gcc-toolset-14/root/usr/bin/gcc
            export CXX=/opt/rh/gcc-toolset-14/root/usr/bin/g++
          fi

          if [ -f "/usr/bin/gcc-11" ] 
          then
            export CC=/usr/bin/gcc-11
            export CXX=/usr/bin/g++-11
          fi

          if [ -f "/usr/bin/gcc-12" ] 
          then
            export CC=/usr/bin/gcc-12
            export CXX=/usr/bin/g++-12
          fi

          chmod 0777 .
          mkdir __build && chown condorauto __build && chmod 0777 __build
          su condorauto -c "cd __build && cmake -GNinja -DWITH_LIBVIRT:bool=false -DWITH_VOMS:bool=false .. && ninja -j 4 install"

      - name: test
        # Use su to run as condorauto user inside container, test_guidance test is flakey
        run: ( su condorauto -c "cd __build && ctest --output-junit test.xml -j 40 -E guidance" )

        # Report the memory used by the build & test run, because I'm curious
      - name: memory usage
        if: always()
        run: |
          su root -c 'cat /sys/fs/cgroup/$(awk -F: "{print \$3}" < /proc/self/cgroup)/memory.peak'
          free -h

      # The upload on fail step frequently fails because running condor
      # processes are mutating files as upload tries to read them, which
      # breaks the upload. So we kill off condor processes first.
      - name: Kill off processes
        if: always()
        run: |
          ps auxww | grep [Cc]ondor_ | awk '{print $2}' | xargs -r kill -9

      - name: Upload All on Failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: test-output-for-${{ matrix.instance.abbrev }}
          path: __build/src/condor_tests
          retention-days: 2
          overwrite: true

      - name: Upload Artifact with Test Results on failure or success
        # Always upload, even if build or tests fail
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: tests-for-${{ matrix.instance.abbrev }}
          path: __build/test.xml
          retention-days: 1
          overwrite: true

  macbuild:
    runs-on: macos-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install python
        uses: actions/setup-python@v5

      - name: Install python accessories
        run: |
          pip install pytest pytest-httpserver

      - name: Build
        run: (mkdir __build && cd __build && cmake -GNinja -DWITH_VOMS:bool=false .. && ninja -j4 install)

  winbuild:
    runs-on: windows-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install VC++ Build Tools
        uses: ilammy/msvc-dev-cmd@v1

      - name: Install perl
        uses: shogo82148/actions-setup-perl@v1
        with:
          distribution: strawberry

      - name: Install/Upgrade python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install/Upgrade python and python accessories
        run: | 
          python -m pip install --upgrade pip setuptools wheel

      - name: cmake configuration
        run: (cmake -G "Visual Studio 17 2022" -DPYTHON_EXECUTABLE="${{ env.pythonLocation }}\python.exe" -DWITH_KRB5:bool=false .)

      - name: build
        run: (cmake --build . --verbose --config Release --parallel 4)

  ubuntunative:
    runs-on: ubuntu-latest

    # Use htcondor build containers for the real work
    container:
      image: htcondor/nmi-build:x86_64_Ubuntu24-25000602
      env:
        OMP_NUM_THREADS: 4
      options: --cpus 4
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build Ubuntu Native Package
        run: ./build-on-linux.sh .

      - name: Upload .debs
        uses: actions/upload-artifact@v4
        with:
          name: debs
          path: |
            *.deb
            /usr/local/condor/externals/pelican*
          if-no-files-found: ignore
          retention-days: 1
          overwrite: true

  ubuntuinstall:
    needs: ubuntunative
    runs-on: ubuntu-latest
    steps:
      - name: Download .debs
        uses: actions/download-artifact@v4
        with:
          merge-multiple: true

      - name: Install HTCondor from .debs
        run: |
          sudo apt update
          # Dunno why but we need to copy them to current dir to install
          sudo cp __w/htcondor/htcondor/condor_*.deb __w/htcondor/htcondor/mini*.deb usr/local/condor/externals/pelican*.deb .
          sudo apt install -y ./*.deb

      - name: Verify condor installation
        run: |
          sudo condor_master
          condor_version
          sleep 5
          condor_status

  ubuntu_root:
    # Run on raw ubuntu, no container
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build Ubuntu 
        run: |
          id
          sudo apt-get install uuid-dev libcurl4-openssl-dev
          sudo pip3 install pytest pytest-httpserver
          mkdir __build && chmod 0777 __build
          cd __build && cmake -GNinja -DWITH_SCITOKENS:bool=false -DWITH_KRB5:bool=false -DWITH_MUNGE:bool=false -DWITH_LIBVIRT:bool=false -DWITH_VOMS:bool=false .. && ninja -j 4 install

      - name: Test with rootness
        # Use su to run as condorauto user inside container, test_guidance test is flakey
        run: ( cd __build && HTCONDOR_TEST_USE_SUDO=1 ctest --output-junit test.xml -j 40 -R test_cgroup_oom )

  dashboard:
    needs: [build, macbuild, winbuild]
    runs-on: ubuntu-latest
    if: always()
    steps:
         - name: Download test xml output artifacts
           uses: actions/download-artifact@v4
           with:
             pattern: tests-for-*

         - name: create_summary
           shell: python
           run: |
             import os
             import sys
             import xml.etree.ElementTree as ET
             from pathlib import Path
             from collections import defaultdict

             results = defaultdict(dict)

             # Parse all test.xml files from downloaded artifacts into the results dict
             for dir in Path(".").iterdir():
               test_xml = dir / 'test.xml'
               for elem in ET.parse(test_xml).getroot().findall("testcase"):
                 testname = elem.get("name")
                 teststatus = ":green_circle:" if elem.get("status") == "run" else ":red_circle:"
                 results[dir][testname] = teststatus

             header = "| test |"
             separator = "|---|"

             for platform in sorted(results.keys()):
               header += f"{platform}|"
               separator += "---|"

             with open(os.environ["GITHUB_STEP_SUMMARY"], "a") as f:
               f.write(header + "\n")
               f.write(separator + "\n")

             alltests = set()
             for platform in results.values():
               for name in platform:
                 alltests.add(name)

             # Print out a line for each test
             for test in sorted(alltests):
               line = f"| {test} |"
               for platform in results.keys():
                 if test in results[platform]:
                   line += f"{results[platform][test]} |"
                 else:
                   line += " - |"
               with open(os.environ["GITHUB_STEP_SUMMARY"], "a") as f:
                 f.write(line + "\n")
