\begin{ManPage}{\label{man-condor-submit}\Condor{submit}}{1}
{Queue jobs for execution under Condor}
\Synopsis \SynProg{\Condor{submit}}
\oOpt{---}
\oOpt{-v}
\oOptArg{-n}{schedd\_name}
\oOptArg{-r}{schedd\_name}
\oOpt{-d}
% this option needs the dots in boldface, so using the macro oOptArg won't work
\Lbr\Opt{-a} \Arg{command} \Opt{\Dots}\Rbr 
\oOpt{-s}
\oArg{submit description file}

\index{Condor commands!condor\_submit}
\index{condor\_submit command}

\Description

\Condor{submit} is the program for submitting jobs for execution
under Condor.
\Condor{submit} requires a submit description file which contains commands
to direct the queuing of jobs.
One submit description file may contain
specifications for the queuing of many Condor jobs at once.
A single invocation of \Condor{submit} may cause one or
more clusters.
A cluster is a set of jobs
specified in the submit description file
between \Opt{queue} commands for which the executable is not changed.
It is advantageous to submit
multiple jobs as a single cluster because:
\begin{itemize}
\item Only one copy of the checkpoint file is needed to 
represent all jobs in a cluster until they begin execution.
\item There is much less overhead involved for Condor to start the next
job in a cluster than for Condor to start a new cluster.  This can make
a big difference when submitting lots of short jobs.
\end{itemize}

Multiple clusters may be specified within a single
submit description file.
Each cluster must specify a single executable.

The job ClassAd attribute \Attr{ClusterId} identifies a cluster.
See section~\ref{user-man-jobad} for specifics on this attribute.

Note that submission of jobs from a Windows machine requires
a stashed password to allow Condor to impersonate the user submitting
the job.
To stash a password, use the \Condor{store\_cred} command.
See the manual page at
page~\pageref{man-condor-store-cred} for details.

\emph{SUBMIT DESCRIPTION FILE COMMANDS}

Each submit description file describes one cluster of jobs to be
placed in the Condor execution pool. All jobs in a cluster must share
the same executable, but they may have different input and output files,
and different program arguments. The submit description file is
the only command-line argument to \Condor{submit}. 

The submit description file must contain one \Arg{executable} command and at least one
\Arg{queue} command.  All of the other commands have default actions.

The commands which can appear in the submit description file are:

\begin{description} 

%%%%%%%%%%%%%%%%%%%
%% executable
%%%%%%%%%%%%%%%%%%%

\item[executable = $<$name$>$]
\index{submit commands!executable}
The name of the executable file for this
job cluster. Only one executable command may be present in a description
file. If submitting into the standard universe, which is the default,
then the named executable must have been re-linked with the Condor
libraries (such as via the \Condor{compile} command). If submitting into
the vanilla universe, then the named executable need not be re-linked and
can be any process which can run in the background (shell scripts work
fine as well).  If submitting into the Java universe, then the argument
must be a compiled \File{.class} file.


%%%%%%%%%%%%%%%%%%%
%% input
%%%%%%%%%%%%%%%%%%%

\item[input = $<$pathname$>$]
\index{submit commands!input}
Condor assumes that its jobs are
long-running, and that the user will not wait at the terminal for their
completion. Because of this, the standard files which normally access
the terminal, (\File{stdin}, \File{stdout}, and \File{stderr}),
must refer to files. Thus,
the file name specified with \Opt{input} should contain any keyboard
input the program requires (that is, this file becomes \File{stdin}).
If not specified, the default value
of \File{/dev/null} is used for submission to a Unix machine.
If not specified, input is ignored
for submission to an NT machine.
For globus universe jobs, \Opt{input} may be a URL that the Globus
tool \Prog{globus\_url\_copy} understands.

%%%%%%%%%%%%%%%%%%%
%% output
%%%%%%%%%%%%%%%%%%%

\item[output = $<$pathname$>$]
\index{submit commands!output}
The \Opt{output} file name will capture
any information the program would normally write to the screen
(that is, this file becomes \File{stdout}).
If not specified, the default value of
\File{/dev/null} is used for submission to a Unix machine.
If not specified, output is ignored
for submission to an NT machine.
More than one job should not use the same output
file, since this will cause one job to overwrite the output of
another.
For globus universe jobs, \Opt{output} may be a URL that the Globus
tool \Prog{globus\_url\_copy} understands.

%%%%%%%%%%%%%%%%%%%
%% error
%%%%%%%%%%%%%%%%%%%

\item[error = $<$pathname$>$]
\index{submit commands!error}
The \Opt{error} file name will capture any
error messages the program would normally write to the screen
(that is, this file becomes \File{stderr}).
If not specified, the default value of
\File{/dev/null} is used for submission to a Unix machine.
If not specified, error messages are ignored
for submission to an NT machine.
More than one job should not use the same error file, since
this will cause one job to overwrite the errors of another.
For globus universe jobs, \Opt{error} may be a URL that the Globus
tool \Prog{globus\_url\_copy} understands.

%%%%%%%%%%%%%%%%%%%
%% arguments
%%%%%%%%%%%%%%%%%%%

\item[arguments = $<$argument\_list$>$]
\index{submit commands!arguments}
List of arguments to be supplied
to the program on the command line.   In the Java Universe, the first
argument must be the name of the class containing \Code{main}.
Arguments are delimited (separated) by space characters.
Jobs submitted for the globus universe will parse arguments
differently 
due to the differences between the ClassAd representation in Condor and 
the Resource Specification Language (RSL) used in Globus.
See section~\ref{sec:CondorG-Submit-Args} for further details.

%%%%%%%%%%%%%%%%%%%
%% initialdir
%%%%%%%%%%%%%%%%%%%

\item[initialdir = $<$directory-path$>$] 
\index{submit commands!initialdir}
Used to specify the current
working directory for the Condor job. Should be a path to a preexisting
directory. If not specified, \Condor{submit} will automatically insert
the user's current working directory at the time \Condor{submit} was run
as the value for \Opt{initialdir}.  If \Opt{initialdir} is specified,
and is not an absolute path, the \Opt{initialdir} value will be appended
to the current working directory, and that will become the working
directory for the Condor job.

%%%%%%%%%%%%%%%%%%%
%% should_transfer_files
%%%%%%%%%%%%%%%%%%%

\item[should\_transfer\_files = $<$YES \Bar\ NO \Bar\ IF\_NEEDED $>$] 
\index{submit commands!should\_transfer\_files}
The \Opt{should\_transfer\_files} setting is used to define if Condor
should transfer files to and from the remote machine where your job
runs.
The file transfer mechanism is used to run jobs which are not in the
standard universe (and can therefore use remote system calls for file
access) on machines which do not have a shared file system with the
submit machine.
\Opt{should\_transfer\_files} equal to \Arg{YES} will cause Condor to
always transfer files for your job.
\Arg{NO} disables Condor's file transfer mechanism.
\Arg{IF\_NEEDED} will not transfer files for your job if it is matched
with a resource in the same \Attr{FileSystemDomain} as your submit
machine (and therefore, on a machine with the same shared file
system).
If the job is matched with a remote resource in a different 
\Attr{FileSystemDomain}, Condor will transfer the necessary files. 

If you define \Opt{should\_transfer\_files} you \emph{must} also
define \Opt{when\_to\_transfer\_output} (described below).
For more information about this and other settings related to
transferring files, see section~\ref{sec:file-transfer} on
page~\pageref{sec:file-transfer}.

Note that \Opt{should\_transfer\_files} is not supported
for jobs submitted to the globus universe.
%%%%%%%%%%%%%%%%%%%
%% when_to_transfer_output
%%%%%%%%%%%%%%%%%%%

\item[when\_to\_transfer\_output = $<$ ON\_EXIT \Bar\ ON\_EXIT\_OR\_EVICT $>$] 
\index{submit commands!when\_to\_transfer\_output}

Setting \Opt{when\_to\_transfer\_output} equal to \Arg{ON\_EXIT} will
cause Condor to transfer the job's output files back to the submitting
machine only when the job completes (exits on its own).

The \Arg{ON\_EXIT\_OR\_EVICT} option is intended for fault tolerant
jobs which periodically save their own state and can restart where
they left off.
In this case, files are transfered to the submit machine any time the
job leaves a remote site, either because it exited on its own, or was
evicted by the Condor system for any reason prior to job completion.
Any output files transferred back to the submit machine are
automatically sent back out again as input files if the job restarts.

For more information about this and other settings related to
transferring files, see section~\ref{sec:file-transfer} on
page~\pageref{sec:file-transfer}.


%%%%%%%%%%%%%%%%%%%
%% transfer_input_files
%%%%%%%%%%%%%%%%%%%

\item[transfer\_input\_files = $<$ file1,file2,file... $>$] 
\index{submit commands!transfer\_input\_files}
Lists all the files to be transferred into the 
working directory for the job before the job is started.
You must separate multiple file names with a comma.
By default, the file specified in the
\Opt{executable} command and any file specified in the \Opt{input}
command (for example, \File{stdin}) are transferred.

Only the transfer of files is available; the transfer of
subdirectories is not supported.

For more information about this and other settings related to
transferring files, see section~\ref{sec:file-transfer} on
page~\pageref{sec:file-transfer}.


%%%%%%%%%%%%%%%%%%%
%% transfer_output_files
%%%%%%%%%%%%%%%%%%%

\item[transfer\_output\_files = $<$ file1,file2,file... $>$] 
\index{submit commands!transfer\_output\_files}
This command forms an explicit list of output files to be transferred
back from the temporary working directory on the execute machine to
the submit machine.
Most of the time, there is no need to use this command.
Other than for globus universe jobs,
if \Opt{transfer\_output\_files} is not specified,
Condor will automatically transfer back all files in the job's
temporary working directory which have been
modified or created by the job.
This is usually the desired behavior.
Explicitly listing output files is typically only done when the job creates
many files, and the user wants to keep a subset of
those files. 
If there are multiple files, they must be delimited with commas.
\Warn Do not specify \Opt{transfer\_output\_files} in the
submit description file unless there is a really good reason -- it is
best to let Condor figure things out by itself based upon what
the job produces.

For globus universe jobs,
to have files other than standard output and standard error transferred
from the execute machine back to the submit machine,
do use \Opt{transfer\_output\_files}, listing
all files to be transferred.
These files are found on the execute machine in the
working directory of the job.

For more information about this and other settings related to
transferring files, see section~\ref{sec:file-transfer} on
page~\pageref{sec:file-transfer}.


%%%%%%%%%%%%%%%%%%%
%% requirements
%%%%%%%%%%%%%%%%%%%

\item[requirements = $<$ClassAd Boolean Expression$>$]
\index{submit commands!requirements}
The requirements
command is a boolean ClassAd expression which uses C-like operators. In
order for any job in this cluster to run on a given machine, this
requirements expression must evaluate to true on the given machine. For
example, to require that whatever machine executes your program has a
least 64 Meg of RAM and has a MIPS performance rating greater than 45,
use: 
\begin{verbatim}
        requirements = Memory >= 64 && Mips > 45
\end{verbatim}
Only one requirements command may be present in a
submit description file.
By default, \Condor{submit} appends the following clauses to
the requirements expression:
\begin{enumerate}
	\item Arch and OpSys are set equal to the Arch and OpSys of the
submit machine.  In other words: unless you request otherwise, Condor will give your
job machines with the same architecture and operating system version as
the machine running \Condor{submit}.
	\item Disk $>=$ DiskUsage. 
The \AdAttr{DiskUsage} attribute is initialized to the size of the
executable plus the size of any files specified in a
\Opt{transfer\_input\_files} command.
It exists to ensure there is enough disk space on the 
target machine for Condor to copy over both the executable
and needed input files.
The \AdAttr{DiskUsage} attribute represents the maximum amount of
total disk space required by the job in kilobytes.
Condor automatically updates the \AdAttr{DiskUsage} attribute
approximately every 20 minutes while the job runs with the
amount of space being used by the job on the execute machine.  
	\item VirtualMemory $>=$ ImageSize.  To ensure the target machine
has enough virtual memory to run your job.
	\item If Universe is set to Vanilla, FileSystemDomain is set equal to
the submit machine's FileSystemDomain.
\end{enumerate}
You can view the requirements of a job
which has already been submitted (along with everything else about the
job ClassAd) with the command \Condor{q -l}; see the command reference for
\Condor{q} on page~\pageref{man-condor-q}.  Also, see the Condor Users
Manual for complete information on the syntax and available attributes
that can be used in the ClassAd expression.


%%%%%%%%%%%%%%%%%%%
%% rank
%%%%%%%%%%%%%%%%%%%

\item[rank = $<$ClassAd Float Expression$>$]
\index{submit commands!rank}
A ClassAd Floating-Point 
expression that states how to rank machines which have already met the requirements
expression. Essentially, rank expresses preference.  A higher numeric value 
equals better rank. Condor will give the job the machine with the 
highest rank.  For example,
\begin{verbatim}
        requirements = Memory > 60
        rank = Memory
\end{verbatim}
asks Condor to find all available machines with more than 60 megabytes of memory
and give the job the one with the most amount of memory.  See the Condor Users
Manual for complete information on the syntax and available attributes
that can be used in the ClassAd expression.

%%%%%%%%%%%%%%%%%%%
%% universe
%%%%%%%%%%%%%%%%%%%

\item[universe = $<$vanilla \Bar\ standard \Bar\ pvm \Bar\ scheduler
\Bar\ globus \Bar\ grid \Bar\ mpi \Bar\ java$>$] 
\index{submit commands!universe}
Specifies which Condor Universe to use when running this job.  The Condor 
Universe specifies a Condor execution environment.  The standard 
Universe is the default (except where the configuration variable
\Macro{DEFAULT\_UNIVERSE} defines it otherwise),
and tells Condor that this job has been re-linked 
via \Condor{compile} with the Condor libraries and therefore supports
checkpointing and remote system calls.  The \Opt{vanilla} Universe is an
execution environment for jobs which have not been linked with the
Condor libraries.  \emph{Note:} Use the \Opt{vanilla} Universe to
submit shell scripts to Condor.  The \Opt{pvm} Universe is for a
parallel job written with PVM 3.4. The \Opt{scheduler} is for a job that
should act as a metascheduler.
The \Opt{globus} universe by default uses the Globus
GRAM API to contact the Globus resource specified and requests it run the job.
The \Opt{globus} and \Opt{grid} universes default to using Globus 2.
Further specification of the \Opt{grid} universe is done with the
\Opt{grid\_type} command.
The \Arg{mpi} universe is
for running mpi jobs made with the MPICH package.
The \Arg{java} Universe is for programs written to the Java Virtual Machine.
See the Condor User's Manual for more information about using Universe.

%%%%%%%%%%%%%%%%%%%
%% grid_type
%%%%%%%%%%%%%%%%%%%
\item[grid\_type = " $<$ gt2 \Bar\ gt3 \Bar\ oracle \Bar\ nordugrid $>$  "] A
\index{submit commands!grid\_type}
case insensitive string to further specify the intended type of resource
for \Opt{grid} or \Opt{globus} universe jobs.
The default value is \Opt{"gt2"}.

%%%%%%%%%%%%%%%%%%%
%% on_exit_remove
%%%%%%%%%%%%%%%%%%%

\item[on\_exit\_remove = $<$ClassAd Boolean Expression$>$] This expression
\index{submit commands!on\_exit\_remove}
is checked when the job exits and if true, then it allows the job to leave the
queue normally. If false, then the job is placed back into the Idle state.
If the user job is a vanilla job then it restarts from the beginning. If the
user job is a standard job, then it restarts from the last checkpoint.

For example:
Suppose you have a job that occasionally segfaults but you know if you run it
again on the same data, chances are it will finish successfully. This is
how you would represent that with \AdAttr{on\_exit\_remove}(assuming the
signal identifier for segmentation fault is 4):

\begin{verbatim}
	on_exit_remove = (ExitBySignal == True) && (ExitSignal != 4)
\end{verbatim}

The above expression will not let the job exit if it exited by a signal and
that signal number was 4(representing segmentation fault). In any other case
of the job exiting, it will leave the queue as it normally would have done.

If left unspecified, this will default to \Expr{True}.

\AdAttr{periodic\_*} expressions take
precedence over \AdAttr{on\_exit\_*} expressions,
and \AdAttr{*\_hold} expressions take
precedence over a \AdAttr{*\_remove} expressions.

This expression is available for the vanilla and java universes.  It
is additionally available, when submitted from a Unix machine, for the
standard universe.  Note that the schedd, by default, only checks
these periodic expressions once every 300 seconds.  The period of
these evaluations can be adjusted by setting the
\Macro{PERIODIC\_EXPR\_INTERVAL} configuration macro.


%%%%%%%%%%%%%%%%%%%
%% on_exit_hold
%%%%%%%%%%%%%%%%%%%

\item[on\_exit\_hold = $<$ClassAd Boolean Expression$>$] This expression
\index{submit commands!on\_exit\_hold}
is checked when the job exits and if true, places the job on hold. If false
then nothing happens and the \AdAttr{on\_exit\_remove} expression is
checked to determine if that needs to be applied.

For example:
Suppose a job is known to run for a minimum of an hour.
If the job exits after less than an hour, the job should be placed on
hold and an e-mail notification sent,
instead of being allowed to leave the queue.

\begin{verbatim}
	on_exit_hold = (CurrentTime - JobStartDate) > (60 * $(MINUTE))
\end{verbatim}

This expression places the job on hold if it exits for any reason
before running for an hour. An e-mail will be sent to the user explaining
that the job was placed on hold because this expression became \Expr{True}.

\AdAttr{periodic\_*} expressions take
precedence over \AdAttr{on\_exit\_*} expressions,
and \AdAttr{*\_hold} expressions take
precedence over a \AdAttr{*\_remove} expressions.

If left unspecified, this will default to \Expr{False}.

This expression is available for the vanilla and java universes.
It is additionally available, when submitted from a Unix machine,
for the standard universe.

%%%%%%%%%%%%%%%%%%%
%% periodic_remove
%%%%%%%%%%%%%%%%%%%

\item[periodic\_remove = $<$ClassAd Boolean Expression$>$]
\index{submit commands!periodic\_remove}
This expression is checked periodically at an interval of
the number of seconds set by
the configuration variable \Macro{PERIODIC\_EXPR\_INTERVAL}.
If it becomes \Expr{True}, the job is removed from the queue.
If unspecified, the default value is \Expr{False}.

See the Examples section for an example of a \AdAttr{periodic\_*}
expression. 

\AdAttr{periodic\_*} expressions take
precedence over \AdAttr{on\_exit\_*} expressions,
and \AdAttr{*\_hold} expressions take
precedence over a \AdAttr{*\_remove} expressions.
So, the \AdAttr{periodic\_remove} expression takes precedent over
the \AdAttr{on\_exit\_remove} expression,
if the two describe conflicting actions.

This expression is available for the vanilla and java universes.
It is additionally available, when submitted from a Unix machine,
for the standard universe.  Note that the schedd, by default, only checks
periodic expressions once every 300 seconds.  The period of
these evaluations can be adjusted by setting the
\Macro{PERIODIC\_EXPR\_INTERVAL} configuration macro.

%%%%%%%%%%%%%%%%%%%
%% periodic_hold
%%%%%%%%%%%%%%%%%%%

\item[periodic\_hold = $<$ClassAd Boolean Expression$>$]
\index{submit commands!periodic\_hold}
This expression is checked periodically at an interval of
the number of seconds set by
the configuration variable \Macro{PERIODIC\_EXPR\_INTERVAL}.
If it becomes true, the job will be placed on hold.
If unspecified, the default value is \Expr{False}.

See the Examples section for an example of a \AdAttr{periodic\_*}
expression. 

\AdAttr{periodic\_*} expressions take
precedence over \AdAttr{on\_exit\_*} expressions,
and \AdAttr{*\_hold} expressions take
precedence over a \AdAttr{*\_remove} expressions.

This expression is available for the vanilla and java universes.
It is additionally available, when submitted from a Unix machine,
for the standard universe.  Note that the schedd, by default, only checks
periodic expressions once every 300 seconds.  The period of
these evaluations can be adjusted by setting the
\Macro{PERIODIC\_EXPR\_INTERVAL} configuration macro.

%%%%%%%%%%%%%%%%%%%
%% periodic_release
%%%%%%%%%%%%%%%%%%%

\item[periodic\_release = $<$ClassAd Boolean Expression$>$]
\index{submit commands!periodic\_release}
This expression is checked periodically at an interval of
the number of seconds set by
the configuration variable \Macro{PERIODIC\_EXPR\_INTERVAL}
while the job is in the Hold state.
If the expression becomes \Expr{True}, the job will be released.

% The expression is evaluated:
%- every time there is a condor_reconfig
%- every time condor_reschedule happens
%- every time condor_submit happens
%- BUT never more often than condor_config SCHEDD_MIN_INTERVAL seconds 
%(default of 5 seconds)
%- AND never less often than condor_config SCHEDD_INTERVAL seconds (defaults 
%to 5 minutes).
%
%So the short answer: by default, every SCHEDD_INTERVAL (5 minutes by 
%default) or more often as needed.

% what universes (other than universe=globus) does this apply to?

This expression is available for the vanilla and java universes.
It is additionally available, when submitted from a Unix machine,
for the standard universe.  Note that the \Condor{schedd} daemon,
by default, only checks
periodic expressions once every 300 seconds.  The period of
these evaluations can be adjusted by setting the
\Macro{PERIODIC\_EXPR\_INTERVAL} configuration macro.


%%%%%%%%%%%%%%%%%%%
%% priority
%%%%%%%%%%%%%%%%%%%

\item[priority = $<$priority$>$] Condor job priorities range from -20 to
\index{submit commands!priority}
+20, with 0 being the default. Jobs with higher numerical priority will
run before jobs with lower numerical priority. Note that this priority
is on a per user basis; setting the priority will determine the order in
which your own jobs are executed, but will have no effect on whether or
not your jobs will run ahead of another user's jobs. 

%%%%%%%%%%%%%%%%%%%
%% notification
%%%%%%%%%%%%%%%%%%%

\item[notification = $<$when$>$]\label{man-condor-submit-notification} Owners of Condor jobs are notified by
\index{submit commands!notification}
email when certain events occur.
If \Arg{when} is set to \mbox{Always}, the owner will be notified
whenever the job is checkpointed, and when it completes.
If \Arg{when} is set to \mbox{Complete} (the default), the owner will
be notified when the job terminates.
If \Arg{when} is set to \mbox{Error}, the owner will only be notified
if the job terminates abnormally.
If \Arg{when} is set to \mbox{Never}, the owner will not be mailed,
regardless what happens to the job.
The statistics included in the email are documented in
section~\ref{sec:job-completion} on
page~\pageref{sec:job-completion}.

%%%%%%%%%%%%%%%%%%%
%% notify_user
%%%%%%%%%%%%%%%%%%%

\item[notify\_user = $<$email-address$>$]\label{man-condor-submit-notify-user} Used to specify the email
\index{submit commands!notify\_user}
address to use when Condor sends email about a job.  If not specified,
Condor will default to using :
\begin{verbatim}
        job-owner@UID_DOMAIN
\end{verbatim}
where \Macro{UID\_DOMAIN} is specified by the Condor site administrator.  If 
\Macro{UID\_DOMAIN} has not been specified, Condor will send the email
to :
\begin{verbatim}
        job-owner@submit-machine-name
\end{verbatim}

%%%%%%%%%%%%%%%%%%%
%% copy_to_spool 
%%%%%%%%%%%%%%%%%%%

\item[copy\_to\_spool = $<$True \Bar\ False$>$] If \Opt{copy\_to\_spool} is set to
\index{submit commands!copy\_to\_spool}
\Expr{True}, then \Condor{submit} will copy the executable to the local spool 
directory before running it on a remote host. Oftentimes this can be quite
time consuming and unnecessary. By setting it to \Expr{False}, \Condor{submit}
will skip this step.  Defaults to \Expr{True}.

%%%%%%%%%%%%%%%%%%%
%% getenv
%%%%%%%%%%%%%%%%%%%

\item[getenv = $<$True \Bar\ False$>$] If \Opt{getenv} is set to
\index{submit commands!getenv}
\index{environment variables!copying current environment}
\Expr{True}, then \Condor{submit} will copy all of the user's current
shell environment variables at the time of job submission into the job
ClassAd. The job will therefore execute with the same set of environment
variables that the user had at submit time. Defaults to \Expr{False}.
%You must be careful when using this feature, since the maximum allowed
%size of the environment in Condor is 10240 characters.  
%If your environment is larger than that, Condor will not allow you to
%submit your job, and you will have to use the ``Environment'' setting
%described below, instead.

%%%%%%%%%%%%%%%%%%%
%% hold
%%%%%%%%%%%%%%%%%%%

\item[hold = $<$True \Bar\ False$>$] If \Opt{hold} is set to
\index{submit commands!hold}
\Expr{True}, then the job will be submitted in the hold state.  Jobs in
the hold state will not run until released by \Condor{release}.
Defaults to false.

%%%%%%%%%%%%%%%%%%%
%% environment
%%%%%%%%%%%%%%%%%%%

\item[environment = $<$parameter\_list$>$] List of environment variables
\index{submit commands!environment}
\index{environment variables!setting, for a job}
of the form :
\begin{verbatim}
        <parameter>=<value>
\end{verbatim}
Multiple environment variables can be specified by separating them with a
semicolon (`` ; '') when submitting from a Unix platform.
Multiple environment variables can be specified by separating them with a
vertical bar (`` | '') when submitting from an NT platform.
These environment variables will be placed (as given) into the
job's environment before execution. The length of all characters
specified in the environment is currently limited to 10240 characters.  
Note that spaces are accepted, but rarely desired,
characters within parameter names and values.
Place spaces within the parameter list only if required.

%%%%%%%%%%%%%%%%%%%
%% log
%%%%%%%%%%%%%%%%%%%

\item[log = $<$pathname$>$] Use \Opt{log} to specify a file name where
\index{submit commands!log}
Condor will write a log file of what is happening with this job cluster.
For example, Condor will log into this file when and where the job
begins running, when the job is checkpointed and/or migrated, when the
job completes, etc. Most users find specifying a \Opt{log} file to be very
handy; its use is recommended. If no \Opt{log} entry is specified, 
Condor does not create a log for this cluster.

\item[log\_xml = $<$True \Bar\ False$>$] If \Opt{log\_xml} is true, 
then the log file will be written in ClassAd XML. If it isn't
specified, XML is not used. Note that it's an XML fragment, and is
missing the file header and footer. Also note that you should never
mix XML and non-XML in a single file: if multiple jobs write to a
single log file, it is up to you to make sure that all of them specify
(or don't specify) this option in the same way.

%%%%%%%%%%%%%%%%%%%
%% jar_files
%%%%%%%%%%%%%%%%%%%

\item[jar\_files = $<$file\_list$>$]
\index{submit commands!jar\_files}
Specifies a list of additional JAR files to include when using
the Java universe.  JAR files will be transferred along with
the executable and automatically added to the classpath.

%%%%%%%%%%%%%%%%%%%
%% image_size
%%%%%%%%%%%%%%%%%%%

\item[image\_size = $<$size$>$] This command tells Condor the maximum
\index{submit commands!image\_size}
virtual image size to which you believe your program will grow during
its execution. Condor will then execute your job only on machines which
have enough resources, (such as virtual memory), to support executing
your job. If you do not specify the image size of your job in the
description file, Condor will automatically make a (reasonably accurate)
estimate about its size and adjust this estimate as your program runs.
If the image size of your job is underestimated, it may crash due to
inability to acquire more address space, e.g. malloc() fails. If the image
size is overestimated, Condor may have difficulty finding machines which
have the required resources. \Arg{size} must be in kbytes, e.g. for
an image size of 8 megabytes, use a \Arg{size} of 8000.

%%%%%%%%%%%%%%%%%%%
%% machine_count
%%%%%%%%%%%%%%%%%%%

\item[machine\_count = $<$min..max$>$ \Bar\ $<$max$>$] 
\index{submit commands!machine\_count}
For the PVM universe,
both \Arg{min} and \Arg{max} or just
\Arg{max} may be defined. 
If \Opt{machine\_count} is
specified, Condor will not start the job until it can simultaneously
supply the job with \Arg{min} machines.  Condor will continue to try 
to provide up
to \Arg{max} machines, but will not delay starting of the job to do so.
If the job is started with fewer than \Arg{max} machines, the job
will be notified via a usual PvmHostAdd notification as additional
hosts come on line.

For the MPI universe, a single value (\Arg{max}) is required.
It is neither a maximum or minimum, but 
the number of machines to be dedicated toward running the job.

%%%%%%%%%%%%%%%%%%%
%% coresize
%%%%%%%%%%%%%%%%%%%

\item[coresize = $<$size$>$] Should the user's program abort and produce
\index{submit commands!coresize}
a core file, \Opt{coresize} specifies the maximum size in bytes of the
core file which the user wishes to keep. If \Opt{coresize} is not
specified in the command file, the system's user resource limit
\mbox{``coredumpsize''} is used.
This limit is not used in HP-UX and DUX operating systems. 

%%%%%%%%%%%%%%%%%%%
%% nice_user
%%%%%%%%%%%%%%%%%%%

\item[nice\_user = $<$True \Bar\ False$>$] \label{man-condor-submit-nice}Normally, when a machine
\index{submit commands!nice\_user}
becomes available to Condor, Condor decides which job to run based upon
user and job priorities. Setting \Opt{nice\_user} equal to \Expr{True}
tells Condor not to use your regular user priority, but that this job
should have last priority among all users and all jobs. So jobs
submitted in this fashion run only on machines which no other
non-nice\_user job wants --- a true ``bottom-feeder'' job! This is very
handy if a user has some jobs they wish to run, but do not wish to use
resources that could instead be used to run other people's Condor jobs. Jobs
submitted in this fashion have ``nice-user.'' pre-appended in front of
the owner name when viewed from \Condor{q} or \Condor{userprio}.  The
default value is \Opt{False}.


%%%%%%%%%%%%%%%%%%%
%% kill_sig
%%%%%%%%%%%%%%%%%%%

\item[kill\_sig = $<$signal-number$>$] When Condor needs to kick a job
\index{submit commands!kill\_sig}
off of a machine, it will send the job the signal specified by
\Arg{signal-number}.  \Arg{signal-number} needs to be an integer which
represents a valid signal on the execution machine.  For jobs submitted
to the Standard Universe, the default value is the number for
\verb@SIGTSTP@ which tells the Condor libraries to initiate a checkpoint
of the process.  For jobs submitted to the Vanilla Universe, the default 
is \verb@SIGTERM@ which is the standard way to terminate a program in UNIX.  

%%%%%%%%%%%%%%%%%%%
%% compress_files
%%%%%%%%%%%%%%%%%%%

\item[compress\_files = file1, file2, ...]
\index{submit commands!compress\_files}

If your job attempts to access any of the files mentioned in this list,
Condor will automatically compress them (if writing) or decompress them (if reading).
The compress format is the same as used by GNU gzip.

The files given in this list may be simple file names or complete paths and may
include $*$ as a wildcard.  For example, this list causes the file /tmp/data.gz,
any file named event.gz, and any file ending in .gzip to be automatically
compressed or decompressed as needed:

\begin{verbatim}
compress_files = /tmp/data.gz, event.gz, *.gzip
\end{verbatim}

Due to the nature of the compression format, compressed files must only
be accessed sequentially.  Random access reading is allowed but is very slow,
while random access writing is simply not possible.  This restriction may be
avoided by using both compress\_files and fetch\_files at the same time.  When
this is done, a file is kept in the decompressed state at the execution
machine, but is compressed for transfer to its original location.

This option only applies to standard-universe jobs.

%%%%%%%%%%%%%%%%%%%
%% fetch_files
%%%%%%%%%%%%%%%%%%%

\item[fetch\_files = file1, file2, ...]

\index{submit commands!fetch\_files}
If your job attempts to access a file mentioned in this list,
Condor will automatically copy the whole file to the executing machine,
where it can be accessed quickly.  When your job closes the file,
it will be copied back to its original location.
This list uses the same syntax as compress\_files, shown above.

This option only applies to standard-universe jobs.

%%%%%%%%%%%%%%%%%%%
%% append_files
%%%%%%%%%%%%%%%%%%%

\item[append\_files = file1, file2, ...]
\index{submit commands!append\_files}

If your job attempts to access a file mentioned in this list,
Condor will force all writes to that file to be appended to the end.
Furthermore, condor\_submit will not truncate it.
This list uses the same syntax as compress\_files, shown above.

This option may yield some surprising results.  If several
jobs attempt to write to the same file, their output may be intermixed.
If a job is evicted from one or more machines during the course of its
lifetime, such an output file might contain several copies of the results.
This option should be only be used when you wish a certain file to be
treated as a running log instead of a precise result.

This option only applies to standard-universe jobs.

%%%%%%%%%%%%%%%%%%%
%% local_files
%%%%%%%%%%%%%%%%%%%

\item[local\_files = file1, file2, ...]
\index{submit commands!local\_files}

If your job attempts to access a file mentioned in this list,
Condor will cause it to be read or written at the execution machine.
This is most useful for temporary files not used for input or output.
This list uses the same syntax as compress\_files, shown above.

\begin{verbatim}
local_files = /tmp/*
\end{verbatim}

This option only applies to standard-universe jobs.

%%%%%%%%%%%%%%%%%%%
%% file_remaps
%%%%%%%%%%%%%%%%%%%

\item[file\_remaps $=$ $<$ `` name $=$ newname ; name2 $=$ newname2 ... ''$>$ ]
\index{submit commands!file\_remaps}

Directs Condor to use a new file name in place of an old one.  \Arg{name}
describes a file name that your job may attempt to open, and \Arg{newname}
describes the file name it should be replaced with.
\Arg{newname} may include an optional leading
access specifier, \verb@local:@ or \verb@remote:@.  If left unspecified,
the default access specifier is \verb@remote:@.  Multiple remaps can be 
specified by separating each with a semicolon.

This option only applies to standard universe jobs.

If you wish to remap file names that contain equals signs or semicolons,
these special characters may be escaped with a backslash.

\begin{description}
\item[Example One:]
Suppose that your job reads a file named \File{dataset.1}.
To instruct Condor
to force your job to read \File{other.dataset} instead, 
add this to the submit file:
\begin{verbatim}
file_remaps = "dataset.1=other.dataset"
\end{verbatim}
\item[Example Two:]
Suppose that your run many jobs which all read in the same large file,
called \File{very.big}.
If this file can be found in the same place on
a local disk in every machine in the pool,
(say \File{/bigdisk/bigfile},) you can
instruct Condor of this fact by remapping \File{very.big} to
\File{/bigdisk/bigfile} and specifying that the file is to be read locally,
which will be much faster than reading over the network.
\begin{verbatim}
file_remaps = "very.big = local:/bigdisk/bigfile"
\end{verbatim}
\item[Example Three:]
Several remaps can be applied at once by separating each with a semicolon.
\footnotesize
\begin{verbatim}
file_remaps = "very.big = local:/bigdisk/bigfile ; dataset.1 = other.dataset"
\end{verbatim}
\normalsize
\end{description}

%%%%%%%%%%%%%%%%%%%
%% buffer_files, buffer_size, buffer_block_size
%%%%%%%%%%%%%%%%%%%

\item[buffer\_files $=$ $<$ `` name $=$ (size,block-size) ; name2 $=$ (size,block-size) ... '' $>$ ]
\item[buffer\_size $=$ $<$bytes-in-buffer$>$]
\item[buffer\_block\_size $=$ $<$bytes-in-block$>$]
\index{submit commands!buffer\_files}
\index{submit commands!buffer\_size}
\index{submit commands!buffer\_block\_size}
Condor keeps a buffer of recently-used data for each file a job accesses.
This buffer is used both to cache commonly-used data and to consolidate small
reads and writes into larger operations that get better throughput.
The default settings should produce reasonable results for most programs.

These options only apply to standard-universe jobs.

If needed, you may set the buffer controls individually for each file using
the buffer\_files option. For example, to set the buffer size to 1 Mbyte and
the block size to 256 KBytes for the file \File{input.data}, use this command:

\begin{verbatim}
buffer_files = "input.data=(1000000,256000)"
\end{verbatim}

Alternatively, you may use these two options to set
the default sizes for all files used by your job:

\begin{verbatim}
buffer_size = 1000000
buffer_block_size = 256000
\end{verbatim}

If you do not set these, Condor will use the values given by these
two configuration file macros:

\begin{verbatim}
DEFAULT_IO_BUFFER_SIZE = 1000000
DEFAULT_IO_BUFFER_BLOCK_SIZE = 256000
\end{verbatim}

Finally, if no other settings are present, Condor will use
a buffer of 512 Kbytes
and a block size of 32 Kbytes.

%%%%%%%%%%%%%%%%%%%
%% rendezvousdir
%%%%%%%%%%%%%%%%%%%

\item[rendezvousdir = $<$directory-path$>$] Used to specify the 
\index{submit commands!rendezvousdir}
shared file system directory to be used for file system authentication
when submitting to a remote scheduler.  Should be a path to a preexisting 
directory.  

%%%%%%%%%%%%%%%%%%%
%% x509directory
%%%%%%%%%%%%%%%%%%%
% 
% \item[x509directory = $<$directory-path$>$] Used to specify the directory 
% \index{submit commands!x509directory}
% which contains the certificate, private key, and trusted certificate directory
% for GSS authentication.
% If this attribute is set, the environment variables 
% X509\_USER\_KEY, X509\_USER\_CERT, and X509\_CERT\_DIR are exported with 
% default values.
%Commented out by Karen for 6.4.3.
%See section~\ref{sec:X509-Authentication} for more information.

%%%%%%%%%%%%%%%%%%%
%% x509userproxy
%%%%%%%%%%%%%%%%%%%

\item[x509userproxy = $<$full-pathname$>$] Used to override the default
\index{submit commands!x509userproxy}
pathname for X509 user certificates. The default location for X509 proxies
is the \File{/tmp} directory,
which is generally a local file system.
Setting
this value would allow Condor to access the proxy in a shared file system
(for example, AFS).
Condor will use the proxy specified in the submit description file first.
If nothing is specified in the submit description file,
it will use the environment variable X509\_USER\_CERT.
If that variable is not present,
it will search in the default location.

%%%%%%%%%%%%%%%%%%%
%% globusscheduler
%%%%%%%%%%%%%%%%%%%

\item[globusscheduler = $<$scheduler-name$>$] Used to specify the 
\index{submit commands!globusscheduler}
Globus resource to which the job should be submitted. More than one scheduler
can be submitted to, simply place a \Arg{queue} command after each instance
of \Opt{globusscheduler}.
Each instance should be a valid Globus scheduler, using
either the full Globus contact string or the host/scheduler format shown below:
\begin{description}
\item[Example:]
To submit to the LSF scheduler of the Globus gatekeeper on lego at 
Boston University:
\begin{verbatim}
GlobusScheduler = lego.bu.edu/jobmanager-lsf
queue
\end{verbatim}
\end{description}

%%%%%%%%%%%%%%%%%%%
%% globusrsl
%%%%%%%%%%%%%%%%%%%

\item[globusrsl = $<$RSL-string$>$] Used to provide any additional Globus RSL
\index{submit commands!globusrsl}
string attributes which are not covered by regular submit description
file parameters.

%%%%%%%%%%%%%%%%%%%
%% globus_resubmit
%%%%%%%%%%%%%%%%%%%

\item[globus\_resubmit = $<$ClassAd Boolean Expression$>$]
\index{submit commands!globus\_resubmit}
The expression is evaluated by the \Condor{gridmanager} each time
the \Condor{gridmanager} gets a job ad to manage.
Therefore, the expression is evaluated:
\begin{enumerate}
\item
   when a globus universe job is first submitted to Condor-G
\item
   when a globus universe job is released from the hold state
\item
   when Condor-G is restarted (specifically, whenever the \Condor{gridmanager}
   is restarted)
\end{enumerate}
If the expression evaluates to \Expr{True},
then any previous submission to the globus universe will be
forgotten and this job will be submitted again as a fresh submission to
the globus universe.
This may be useful if there is a desire to give up on a
previous submission and try again.
Note that this may result in the same job running more than
once.  Do not treat this operation lightly.

%%%%%%%%%%%%%%%%%%%
%% globus_rematch
%%%%%%%%%%%%%%%%%%%

\item[globus\_rematch = $<$ClassAd Boolean Expression$>$]
\index{submit commands!globus\_rematch}
This expression is evaluated by the \Condor{gridmanager} whenever:
\begin{enumerate}
\item
   the \Opt{globus\_resubmit} expression evaluates to \Expr{True}
\item
   the \Condor{gridmanager} decides it needs to retry a submission
   (as when a previous submission failed to commit)
\end{enumerate}
If \Opt{globus\_rematch} evaluates to \Expr{True},
then \emph{before} the job is submitted again to globus,
the \Condor{gridmanager} will request that the \Condor{schedd}
daemon renegotiate
with the matchmaker (the \Condor{negotiator}).
The result is this job will be matched again.

%%%%%%%%%%%%%%%%%%%
%% leave_in_queue
%%%%%%%%%%%%%%%%%%%

\item[leave\_in\_queue = $<$ClassAd Boolean Expression$>$] 
\index{submit commands!leave\_in\_queue}
When the ClassAd Expression evaluates to \Expr{True}, the job is
not removed from the queue upon completion.
The job remains in the queue until the user runs \Condor{rm}
to remove the job from the queue.
This allows the user of a remotely spooled job to retrieve output
files in cases where Condor would have removed them as part of
the cleanup associated with completion.
Defaults to \Expr{False}.

%%%%%%%%%%%%%%%%%%%
%% match_list_length
%%%%%%%%%%%%%%%%%%%

\item[match\_list\_length = $<$integer value$>$] 
\index{submit commands!match\_list\_length}
Defaults to the value zero (0).
When \Opt{match\_list\_length} is defined with an integer value
greater than zero (0),
attributes are inserted into the job ClassAd.
The maximum number of attributes defined is given by the integer
value.
The job ClassAds introduced are given as
\begin{verbatim} 
LastMatchName0 = "most-recent-Name"
LastMatchName1 = "next-most-recent-Name"
\end{verbatim} 

The value for each introduced ClassAd is given by the
value of the \Attr{Name} attribute 
from the machine ClassAd of a previous execution (match).
As a job is matched, the definitions for these attributes
will roll, 
with \verb@LastMatchName1@ becoming \verb@LastMatchName2@,
\verb@LastMatchName0@ becoming \verb@LastMatchName1@,
and \verb@LastMatchName0@ being set by the most recent
value of the \Attr{Name} attribute.

An intended use of 
these job attributes is in the requirements expression.
The requirements can allow a job to prefer a match with either the same
or a different resource than a previous match.

%%%%%%%%%%%%%%%%%%%
%% transfer_output
%%%%%%%%%%%%%%%%%%%
\item[transfer\_output = $<$True \Bar\ False$>$]
\index{submit commands!transfer\_output}
For jobs submitted to the globus universe only.
If \Expr{True}, then the output (from \File{stdout}) from the job
is transferred from the remote machine back to the submit machine.
The name of the file after transfer is given
by the \Opt{output} command.
If \Expr{False}, no transfer takes place (from the remote machine
to submit machine),
and the name of the file is given
by the \Opt{output} command.
The default value is \Expr{True}.

For transferring files other than \File{stdout},
see \Opt{transfer\_output\_files}.

%%%%%%%%%%%%%%%%%%%
%% transfer_input
%%%%%%%%%%%%%%%%%%%
\item[transfer\_input = $<$True \Bar\ False$>$]
\index{submit commands!transfer\_input}
For jobs submitted to the globus universe only.
If \Expr{True}, then the job input (\File{stdin}) is transferred
from the machine where the job was submitted to the remote machine.
The name of the file that is transferred is given by the
\Opt{input} command.
If \Expr{False}, then the job's input is taken from a pre-staged
file on the remote machine, and
the name of the file is given by the \Opt{input} command.
The default value is \Expr{True}.

For transferring files other than \File{stdin},
see \Opt{transfer\_input\_files}.

%%%%%%%%%%%%%%%%%%%
%% transfer_error
%%%%%%%%%%%%%%%%%%%
\item[transfer\_error = $<$True \Bar\ False$>$]
\index{submit commands!transfer\_error}
For jobs submitted to the globus universe only.
If \Expr{True}, then the error output (from \File{stderr}) from the job
is transferred from the remote machine back to the submit machine.
The name of the file after transfer is given
by the \Opt{error} command.
If \Expr{False}, no transfer takes place (from the remote machine
to submit machine),
and the name of the file is given
by the \Opt{error} command.
The default value is \Expr{True}.

%%%%%%%%%%%%%%%%%%%
%% transfer_executable
%%%%%%%%%%%%%%%%%%%

\item[transfer\_executable = $<$True \Bar\ False$>$]
For jobs submitted to the globus universe, as well as vanilla and MPI.
If \Opt{transfer\_executable} is set to
\index{submit commands!transfer\_executable}
\Expr{False}, then Condor looks for the executable on the remote machine, and
does not transfer the executable over.
This is useful if you have already pre-staged your
executable and wish to have Condor behave more like rsh.
Defaults to \Expr{True}.
The default value is \Expr{True}.

%%%%%%%%%%%%%%%%%%%
%% remote_initialdir
%%%%%%%%%%%%%%%%%%%
\item[remote\_initialdir = $<$directory-path$>$] 
\index{submit commands!remote\_initialdir}
For jobs submitted to the globus universe only,
the path specifies the directory in which the job is to be
executed on the remote machine.

%%%%%%%%%%%%%%%%%%%
%% stream_input
%%%%%%%%%%%%%%%%%%%
\item[stream\_input = $<$True \Bar\ False$>$] 
\index{submit commands!stream\_output}
if \Expr{True}, then \File{stdout} is streamed back to
the machine from which the job was submitted. 
If \Expr{False}, \File{stdout} is stored locally
and transferred back when the job completes.
This command is ignored if the job ClassAd attribute
\Attr{TransferOut} is
\Expr{False}.
The default value is \Expr{True} in the Globus
universe and \Expr{False} otherwise.

%%%%%%%%%%%%%%%%%%%
%% stream_output
%%%%%%%%%%%%%%%%%%%
\item[stream\_output = $<$True \Bar\ False$>$] 
\index{submit commands!stream\_output}
if \Expr{True}, then \File{stdout} is streamed back to
the machine from which the job was submitted. 
If \Expr{False}, \File{stdout} is stored locally
and transferred back when the job completes.
This command is ignored if the job ClassAd attribute
\Attr{TransferOut} is
\Expr{False}.
The default value is \Expr{True} in the Globus
universe and \Expr{False} otherwise.

%%%%%%%%%%%%%%%%%%%
%% stream_error
%%%%%%%%%%%%%%%%%%%
\item[stream\_error = $<$True \Bar\ False$>$] 
\index{submit commands!stream\_error}
if \Expr{True}, then \File{stderr} is streamed back to
the machine from which the job was submitted. 
If \Expr{False}, \File{stderr} is stored locally
and transferred back when the job completes.
This command is ignored if the job ClassAd attribute
\Attr{TransferErr} is
\Expr{False}.
The default value is \Expr{True} in the Globus
universe and \Expr{False} otherwise.

%%%%%%%%%%%%%%%%%%%
%% job_lease_duration
%%%%%%%%%%%%%%%%%%%
\item[job\_lease\_duration = $<$number-of-seconds$>$] 
\index{submit commands!job\_lease\_duration}
\Todo
%%%%%%%%%%%%%%%%%%%
% +
%%%%%%%%%%%%%%%%%%%

\item[+$<$attribute$>$ = $<$value$>$] A line which begins with a '+'
(plus) character instructs \Condor{submit} to insert the
following \Arg{attribute} into the job ClasssAd with the given 
\Arg{value}. 

%%%%%%%%%%%%%%%%%%%
%% queue
%%%%%%%%%%%%%%%%%%%

% these do not put the right bracket on the same line
% \item[queue \Lbr number-of-procs \Rbr] Places one or more 
% \item[queue $[$number-of-procs$]$] Places one or more 
% this also doesn't work, but Karen doesn't know what else to try,
% and it isn't worth the time.
\item[queue \oOptnm{number-of-procs}] Places one or more
\index{submit commands!queue}
copies of the job into
the Condor queue. 
The optional
argument \Arg{number-of-procs} specifies how many times to submit the
job to the queue, and it defaults to 1.
If desired, any commands may be placed
between subsequent \Opt{queue} commands, such as new \Opt{input},
\Opt{output}, \Opt{error}, \Opt{initialdir}, \Opt{arguments}, or
\Opt{executable} commands.
This is handy when submitting multiple runs into one cluster with
one submit description file.
Multiple clusters may be specified within a single 
submit description file by changing the executable between
\Opt{queue} commands.
Each time the \Opt{executable} command is issued (between \Opt{queue} commands),
a new cluster is defined.

%%%%%%%%%%%%%%%%%%%
%% allow_startup_script
%%%%%%%%%%%%%%%%%%%
\item[allow\_startup\_script = $<$True \Bar\ False$>$]
\index{submit commands!allow\_startup\_script}
If True, a standard universe job will execute a script
instead of submitting the job,
and the consistency check to see if the executable has
been linked using \Condor{compile} is omitted.
The \Opt{executable} command within the submit description
file specifies the name of the script.
The script is used to do preprocessing before the
job is submitted.
The shell script ends with an \Prog{exec} of the
job executable, such that the process id of the executable is the
same as that of the shell script.
Here is an example script that gets a copy of a machine-specific
executable before the \Prog{exec}.
\begin{verbatim} 
   #! /bin/sh

   # get the host name of the machine
   $host=`uname -n`

   # grab a standard universe executable designed specifically
   # for this host
   scp elsewhere@cs.wisc.edu:${host} executable

   # The PID MUST stay the same, so exec the new standard universe process.
   exec executable ${1+"$@"}
\end{verbatim} 
If this command is not present (defined), then the value
defaults to false.

\end{description}

In addition to commands, the submit description file can contain macros
and comments:
\index{macro!in submit description file}

\begin{description}

\item[Macros] Parameterless macros in the form of \MacroUNI{macro\_name}
may be inserted anywhere in Condor submit description files. Macros can be
defined by lines in the form of 
\begin{verbatim} 
        <macro_name> = <string> 
\end{verbatim} 
Three pre-defined macros are supplied by the submit description file parser.
The third of the pre-defined macros is only relevant to MPI universe
jobs.
The
\MacroU{Cluster} macro supplies the value of the
\index{ClassAd job attribute!ClusterId}
\index{ClusterId!job ClassAd attribute}
\index{job ID!cluster identifier}
\Attr{ClusterId} job
ClassAd attribute, and the
\MacroU{Process} macro supplies the value of the
\Attr{ProcId} job
ClassAd attribute.
These macros are
intended to aid in the specification of input/output files, arguments,
etc., for clusters with lots of jobs, and/or could be used to supply a
Condor process with its own cluster and process numbers on the command
line.  The \MacroU{Process} macro should not be used for PVM jobs.
The 
\MacroU{Node} macro is defined only for MPI universe jobs.
It is a unique value assigned for the duration of the job
that essentially identifies the machine on which a program is
executing.

If the dollar sign (``\$'') is desired as a literal character,
then use
\begin{verbatim}
$(DOLLAR)
\end{verbatim}

In addition to the normal macro, there is also a special kind of macro
called a \Term{substitution macro} that allows you to substitute
expressions defined on the resource machine itself (gotten after a match
to the machine has been performed) into specific expressions in your
submit description file. The special substitution macro is of the form:
\begin{verbatim} 
$$(attribute)
\end{verbatim}

\index{substitution macro!in submit description file}
The substitution macro may only be used in three expressions in the
submit description file: \MacroNI{executable}, \MacroNI{environment}, and
\MacroNI{arguments}. The most common use of this macro is for heterogeneous
submission of an executable:
\begin{verbatim}
executable = povray.$$(opsys).$$(arch)
\end{verbatim}
The \AdAttr{opsys} and \AdAttr{arch} attributes will be substituted at
match time for any given resource. This will allow Condor to automatically
choose the correct executable for the matched machine.

An extension to the syntax of the substitution macro provides an
alternative string to use if the machine attribute within the
substitution macro is undefined.
The syntax appears as:
\begin{verbatim} 
$$(attribute:string_if_attribute_undefined)
\end{verbatim}

An example using this extended syntax provides a path name to a
required input file.
Since the file can be placed in different locations on
different machines, the file's path name is given as an argument
to the program.
\begin{verbatim} 
argument = $$(input_file_path:/usr/foo)
\end{verbatim}
On the machine, if the attribute \Attr{input\_file\_path} is not
defined, then the path \File{/usr/foo} is used instead.

\index{\$ENV!in submit description file}
\index{submit commands!\$ENV macro}
\index{environment variables!in submit description file}
The environment macro, \$ENV, allows the evaluation of an environment
variable to be used in setting a submit description file command.
The syntax used is
\begin{verbatim} 
$ENV(variable)
\end{verbatim}
An example submit description file command that uses this functionality
evaluates the submitter's home directory in order to set the
path and file name of a log file:
\begin{verbatim} 
log = $ENV(HOME)/jobs/logfile
\end{verbatim}
The environment variable is evaluated when the submit description
file is processed.

\index{\$RANDOM\_CHOICE()!in submit description file}
\index{submit commands!\$RANDOM\_CHOICE() macro}
\index{RANDOM\_CHOICE() macro!use in submit description file}
The \$RANDOM\_CHOICE macro allows a random choice to be made
from a given list of parameters at submission time.
For an expression, if some randomness needs to be generated,
the macro may appear as
\begin{verbatim} 
    $RANDOM_CHOICE(0,1,2,3,4,5,6)
\end{verbatim}
When evaluated, one of the parameters values will be chosen. 

\item[Comments] Blank lines and lines beginning with a 
pound sign
('\#')
character are ignored by the submit description file parser. 

\end{description}


\begin{Options}

\OptItem{\Opt{---}}{Accept the command file from stdin.}
\OptItem{\Opt{-v}}{Verbose output - display the created job class-ad}

\OptItem{\OptArg{-n}{schedd\_name}}{Submit to the specified schedd. This option is used when there is more than one schedd running on the submitting machine}

\OptItem{\OptArg{-r}{schedd\_name}}{Submit to a remote schedd. The jobs
will be submitted to the schedd on the specified remote host. On Unix
systems, the Condor administrator for you site must override the default 
AUTHENTICATION\_METHODS configuration setting to enable remote file system 
(FS\_REMOTE) authentication.}

\OptItem{\Opt{-d}}{Disable file permission checks.}

\OptItem{\OptArg{-a}{command}}{Augment the commands in the submit 
description file with the given command.
This command will be considered to immediately precede the Queue
command within the submit description file, and come after all other
previous commands.
The submit description file is not modified.
Multiple commands are specified by using the \Opt{-a} option multiple times.
Each new command is given in a separate \Opt{-a} option.
Commands with spaces in them will need to be enclosed in double quote
marks.}

\OptItem{\Opt{-s}}{Spool all required input files, user log, and
proxy to the machine defined by the \Macro{SCHEDD\_HOST} configuration
variable.
This is an alternative way to accomplish the same as using
the 
\OptArg{-r}{schedd\_name} option.
With the 
\Opt{-s} option, the remote \Condor{schedd} is specified using
a configuration variable instead of a command line argument.}

\OptItem{submit description file}{The pathname to the submit description
file. If this optional argument is missing, then the commands are
taken from standard input.}

\end{Options}

\ExitStatus

\Condor{submit} will exit with a status value of 0 (zero) upon success, and a
non-zero value upon failure.

\Examples

\begin{itemize} 
\item{Submit Description File Example 1:} This example queues three jobs for
execution by Condor. The first will be given command line arguments of
\Arg{15} and \Arg{2000}, and it will write its standard output
to \File{foo.out1}.
The second will be given command line arguments of 
\Arg{30} and \Arg{2000}, and it will
write its standard output to \File{foo.out2}.
Similarly the third will have
arguments of 
\Arg{45} and \Arg{6000}, and it will use \File{foo.out3} for its standard
output. Standard error output (if any) from all three programs will
appear in \File{foo.error}.

\begin{verbatim}
      ####################
      #
      # submit description file
      # Example 1: queuing multiple jobs with differing
      # command line arguments and output files.
      #                                                                      
      ####################                                                   
                                                                         
      Executable     = foo                                                   
      Universe       = standard
                                                                         
      Arguments      = 15 2000                                               
      Output  = foo.out1                                                     
      Error   = foo.err1
      Queue                                                                  
                                                                         
      Arguments      = 30 2000                                               
      Output  = foo.out2                                                     
      Error   = foo.err2
      Queue                                                                  
                                                                         
      Arguments      = 45 6000                                               
      Output  = foo.out3                                                     
      Error   = foo.err3
      Queue                   
\end{verbatim}

\item{Submit Description File Example 2:} This submit description file
example queues 150
runs of program \Prog{foo} which must have been compiled and linked for
Silicon Graphics workstations running IRIX 6.x.
Condor will not attempt
to run the processes on machines which have less than 32 Megabytes of
physical memory, and it will run them on machines which have at least 64
Megabytes, if such machines are available.
Stdin, stdout, and stderr will
refer to \File{in.0}, \File{out.0}, and \File{err.0} for the first run
of this program (process 0).
Stdin, stdout, and stderr will refer to
\File{in.1}, \File{out.1}, and \File{err.1} for process 1, and so forth.
A log file containing entries
about where and when Condor runs, takes checkpoints, and migrates processes
in this cluster will be written into file \File{foo.log}.

\begin{verbatim}
      ####################                                                    
      #                                                                       
      # Example 2: Show off some fancy features including
      # use of pre-defined macros and logging.                                
      #                                                                       
      ####################                                                    
                                                                          
      Executable     = foo                                                    
      Universe       = standard
      Requirements   = Memory >= 32 && OpSys == "IRIX6" && Arch =="SGI"     
      Rank           = Memory >= 64
      Image_Size     = 28 Meg                                                 
                                                                          
      Error   = err.$(Process)                                                
      Input   = in.$(Process)                                                 
      Output  = out.$(Process)                                                
      Log = foo.log                                                                       
                                                                          
      Queue 150
\end{verbatim}

\item{Command Line example:} The following command uses the
\Opt{-a} option to add two commands before the job(s) is queued.
A log file and an error log file are specified.
The submit description file is unchanged.
\footnotesize
\normalsize
\begin{verbatim}
condor_submit -a "log = out.log" -a "error = error.log" mysubmitfile
\end{verbatim}
Note that each of the added commands is contained within quote marks
because there are space characters within the command.

\item{\AdAttr{periodic\_remove} example:}
A job should be removed from the queue,
if the total suspension time of the job
is more than half of the run time of the job.

Including the command
\footnotesize
\begin{verbatim}
   periodic_remove = CumulativeSuspensionTime > 
                     ((RemoteWallClockTime - CumulativeSuspensionTime) / 2.0)
\end{verbatim}
\normalsize
in the submit description file causes this to happen.

\end{itemize} 


\GenRem
\begin{itemize}

\item For security reasons, Condor will refuse to run any jobs submitted
by user root (UID = 0) or by a user whose default group is group wheel
(GID = 0). Jobs submitted by user root or a user with a default group of
wheel will appear to sit forever in the queue in an idle state. 

\item All pathnames specified in the submit description file must be
less than 256 characters in length, and command line arguments must be
less than 4096 characters in length; otherwise, \Condor{submit} gives a
warning message but the jobs will not execute properly. 

\item Somewhat understandably, behavior gets bizarre if the user makes
the mistake of requesting multiple Condor jobs to write to the
same file, and/or if the user alters any files that need to be accessed
by a Condor job which is still in the queue.
For example, the compressing of data or
output files before a Condor job has completed is a common mistake.

\item To disable checkpointing for Standard Universe jobs, include the
line:
\begin{verbatim}
      +WantCheckpoint = False
\end{verbatim}
in the submit description file before the queue command(s).
\end{itemize}

\SeeAlso
Condor User Manual

\end{ManPage}

